{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "unsupervised_learning_image_rotations.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOfP44MmgzLCPIeDefpFAeh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vantage-AI/blog_rotations/blob/master/unsupervised_learning_image_rotations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUI0p3EEU1k-",
        "colab_type": "text"
      },
      "source": [
        "# Unsupervised representation learning\n",
        "This notebook shows how one can do unsupervised representation learning, similar to [this paper](https://arxiv.org/pdf/1803.07728.pdf). \n",
        "\n",
        "We train a model on the [fashion mnist dataset](https://github.com/zalandoresearch/fashion-mnist). The model we use is described [here](https://github.com/zalandoresearch/fashion-mnist/blob/master/benchmark/convnet.py). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSHVOcZYMjdI",
        "colab_type": "text"
      },
      "source": [
        "## Initialize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gAECrSdEMHFt",
        "colab_type": "code",
        "outputId": "455aa7b7-6180-4bd9-a3d3-de56ff3d3587",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "import numpy as np\n",
        "from matplotlib import colors\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import itertools\n",
        "\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "# tf.enable_eager_execution()\n",
        "print(f\"Tensorflow version: {tf.__version__}; GPU available: {tf.test.is_gpu_available()}\") # default version of tensorflow is still 1.15, will change to 2.x soon\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-1-13c668d453cb>:14: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.config.list_physical_devices('GPU')` instead.\n",
            "Tensorflow version: 2.2.0; GPU available: True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9XcyXDjPcN4",
        "colab_type": "code",
        "outputId": "842fc409-0f45-4eff-9d0a-68bb33e699e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import sklearn\n",
        "print(sklearn.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.22.2.post1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SsVBr-AUMnQ2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 1024\n",
        "PATIENCE = 5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KxHTaa_JCcbA",
        "colab_type": "text"
      },
      "source": [
        "## Useful functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0zMborKCd7C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate_performance(model, features, labels):\n",
        "    probas = model.predict(features)\n",
        "    print(probas.shape)\n",
        "    preds = probas.argmax(axis=1)\n",
        "    print(classification_report(labels, preds))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GnDWUPytCenv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rot90(x, y):\n",
        "  return tf.image.rot90(x, k=y), y\n",
        "\n",
        "def create_unsupervised_dataset(features):\n",
        "  \"\"\"Create a tensorflow dataset where the labels are rotations.\"\"\"\n",
        "  N = len(features)\n",
        "  labels = np.random.choice(range(4), size=N).astype(np.int32)\n",
        "  features_dataset = tf.data.Dataset.from_tensor_slices(features) \n",
        "  labels_dataset = tf.data.Dataset.from_tensor_slices(labels) \n",
        "  dataset = tf.data.Dataset.zip((features_dataset, labels_dataset)) \n",
        "  dataset = dataset.map(rot90)\n",
        "  dataset = dataset.shuffle(buffer_size=1024).batch(BATCH_SIZE)\n",
        "  return dataset\n",
        "\n",
        "def create_supervised_dataset(features, labels):\n",
        "  \"\"\"Create a dataset with regular labels.\"\"\"\n",
        "  features_dataset = tf.data.Dataset.from_tensor_slices(features) \n",
        "  labels_dataset = tf.data.Dataset.from_tensor_slices(labels) \n",
        "  dataset = tf.data.Dataset.zip((features_dataset, labels_dataset)) \n",
        "  dataset = dataset.shuffle(buffer_size=1024).batch(BATCH_SIZE)\n",
        "  return dataset\n",
        "\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        " \n",
        "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py\n",
        "    \"\"\"\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        " \n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        " \n",
        "    fmt = '.3f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        " \n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RtEWV7kGMvGw",
        "colab_type": "text"
      },
      "source": [
        "## Get dataset\n",
        "We download the dataset and preprocess it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XREgmd1rTkT4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load data from https://www.openml.org/d/554\n",
        "X, y = fetch_openml('Fashion-MNIST', version=1, return_X_y=True)\n",
        "labelmap = {0:\"T-shirt/top\",\n",
        "1:\t\"Trouser\",\n",
        "2:\t\"Pullover\",\n",
        "3:\t\"Dress\",\n",
        "4:\t\"Coat\",\n",
        "5:\t\"Sandal\",\n",
        "6:\t\"Shirt\",\n",
        "7:\t\"Sneaker\",\n",
        "8:\t\"Bag\",\n",
        "9: \"Ankle boot\"}\n",
        "\n",
        "# (X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# labelmap = {0:\"airplane\",\n",
        "# 1:\"automobile\",\t\t\t\t\n",
        "# 2:'bird',\t\t\t\t\t\t\t\n",
        "# 3:'cat',\t\t\t\t\t\t\t\t\t\n",
        "# 4:'deer',\t\t\t\t\t\t\t\t\t\t\n",
        "# 5:'dog',\t\t\t\t\t\t\t\t\t\n",
        "# 6:'frog',\t\t\t\t\t\t\t\t\t\t\n",
        "# 7:\"horse\",\t\t\t\t\t\t\t\t\t\t\n",
        "# 8:\"ship\",\t\t\t\t\t\t\t\t\t\n",
        "# 9:\"truck\"}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fozji-hvnGZa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = X.reshape((-1, 28, 28, 1))\n",
        "X_train = X[:60000]\n",
        "X_test = X[60000:]\n",
        "y_train = y[:60000]\n",
        "y_test = y[60000:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9ocrN9uTo6h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# NOrmalize pixel values to be in the range [0, 1].\n",
        "X_train = (X_train / 255.).astype(np.float32)\n",
        "X_test = (X_test / 255.).astype(np.float32)\n",
        "y_train = y_train.astype(np.int32)\n",
        "y_test = y_test.astype(np.int32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLYewtJwTvjc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Leave out 1000 images as the \"labelled\" set.\n",
        "X_labelled = X_train[:1000] # leave these 1000 out, we will assume this is the set of labeled images\n",
        "y_labelled = y_train[:1000]\n",
        "\n",
        "# Use the other images without their labels\n",
        "X_train, X_val = X_train[1000:50000], X_train[50000:60000]\n",
        "y_train, y_val  = y_train[1000:50000], y_train[50000:60000]\n",
        "\n",
        "\n",
        "train_dataset = create_unsupervised_dataset(X_train)\n",
        "val_dataset = create_unsupervised_dataset(X_val)\n",
        "test_dataset = create_unsupervised_dataset(X_test)\n",
        "\n",
        "val_dataset_labelled = create_supervised_dataset(X_val, y_val)\n",
        "test_dataset_labelled = create_supervised_dataset(X_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTnKDzDzspPP",
        "colab_type": "code",
        "outputId": "9ded3333-8f20-4e61-c8cc-ec82b0085ac6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "for x, label in train_dataset:\n",
        "  break\n",
        "ind = 0\n",
        "d_rot = {0:0, 1:90, 2:180, 3:270}\n",
        "print(f\"Label: {d_rot[label[ind].numpy()]} deg counterclockwise\")\n",
        "plt.imshow(np.squeeze(x[ind].numpy()), cmap='gray');"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label: 180 deg counterclockwise\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DOa_rp8KctYS",
        "colab_type": "text"
      },
      "source": [
        "## Model 1: Rotation predictor\n",
        "This model attempts to predict if the picture has been rotated by 0, 90, 180 or 270 degrees."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hrgq6YXcTwIt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_1 = tf.keras.Sequential([tf.keras.layers.Input(shape=(28, 28, 1)),\n",
        "                               tf.keras.layers.Conv2D(32, (5, 5), activation=tf.nn.relu, padding='same', name='conv1'),\n",
        "                               tf.keras.layers.MaxPool2D((2, 2)),\n",
        "                               tf.keras.layers.Conv2D(64, (5, 5), activation=tf.nn.relu, padding='same', name='conv2'),\n",
        "                               tf.keras.layers.GlobalAveragePooling2D(),\n",
        "                               tf.keras.layers.Flatten(),\n",
        "                               tf.keras.layers.Dropout(0.2, name='dropout'),\n",
        "                               tf.keras.layers.Dense(units=16, activation=tf.nn.relu, name='dense'), \n",
        "                               tf.keras.layers.Dense(units=4, activation='softmax', name='output')])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GfsePfdT7o2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_1.compile(optimizer=tf.keras.optimizers.Adam(lr=1e-2), \n",
        "                           loss='sparse_categorical_crossentropy', \n",
        "                           metrics=['sparse_categorical_accuracy']\n",
        "                          )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9Ky-8oJu3np",
        "colab_type": "code",
        "outputId": "8761885e-c5b8-4ed9-a8f7-ec0caaa01397",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "model_1.summary()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1 (Conv2D)               (None, 28, 28, 32)        832       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2 (Conv2D)               (None, 14, 14, 64)        51264     \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 16)                1040      \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 4)                 68        \n",
            "=================================================================\n",
            "Total params: 53,204\n",
            "Trainable params: 53,204\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqix9S5oT-Qy",
        "colab_type": "code",
        "outputId": "58260598-dd46-4b4f-bf3e-1ff49c745ab6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 819
        }
      },
      "source": [
        "\n",
        "model_1.fit(train_dataset,\n",
        "      epochs=int(1e2),\n",
        "      validation_data=val_dataset, \n",
        "      callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)], \n",
        "      verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "48/48 [==============================] - 5s 106ms/step - loss: 1.2499 - sparse_categorical_accuracy: 0.3710 - val_loss: 0.9691 - val_sparse_categorical_accuracy: 0.5354\n",
            "Epoch 2/100\n",
            "48/48 [==============================] - 5s 97ms/step - loss: 0.8246 - sparse_categorical_accuracy: 0.6717 - val_loss: 0.5079 - val_sparse_categorical_accuracy: 0.8280\n",
            "Epoch 3/100\n",
            "48/48 [==============================] - 5s 103ms/step - loss: 0.4977 - sparse_categorical_accuracy: 0.8279 - val_loss: 0.3731 - val_sparse_categorical_accuracy: 0.8839\n",
            "Epoch 4/100\n",
            "48/48 [==============================] - 5s 100ms/step - loss: 0.3944 - sparse_categorical_accuracy: 0.8728 - val_loss: 0.3014 - val_sparse_categorical_accuracy: 0.9077\n",
            "Epoch 5/100\n",
            "48/48 [==============================] - 5s 104ms/step - loss: 0.3245 - sparse_categorical_accuracy: 0.8973 - val_loss: 0.2435 - val_sparse_categorical_accuracy: 0.9283\n",
            "Epoch 6/100\n",
            "48/48 [==============================] - 5s 102ms/step - loss: 0.2721 - sparse_categorical_accuracy: 0.9149 - val_loss: 0.2155 - val_sparse_categorical_accuracy: 0.9368\n",
            "Epoch 7/100\n",
            "48/48 [==============================] - 5s 102ms/step - loss: 0.2428 - sparse_categorical_accuracy: 0.9233 - val_loss: 0.1812 - val_sparse_categorical_accuracy: 0.9475\n",
            "Epoch 8/100\n",
            "48/48 [==============================] - 5s 108ms/step - loss: 0.2116 - sparse_categorical_accuracy: 0.9339 - val_loss: 0.1643 - val_sparse_categorical_accuracy: 0.9510\n",
            "Epoch 9/100\n",
            "48/48 [==============================] - 5s 107ms/step - loss: 0.1957 - sparse_categorical_accuracy: 0.9378 - val_loss: 0.1493 - val_sparse_categorical_accuracy: 0.9568\n",
            "Epoch 10/100\n",
            "48/48 [==============================] - 5s 100ms/step - loss: 0.1792 - sparse_categorical_accuracy: 0.9434 - val_loss: 0.1577 - val_sparse_categorical_accuracy: 0.9529\n",
            "Epoch 11/100\n",
            "48/48 [==============================] - 5s 100ms/step - loss: 0.1730 - sparse_categorical_accuracy: 0.9454 - val_loss: 0.1347 - val_sparse_categorical_accuracy: 0.9595\n",
            "Epoch 12/100\n",
            "48/48 [==============================] - 5s 106ms/step - loss: 0.1588 - sparse_categorical_accuracy: 0.9490 - val_loss: 0.1257 - val_sparse_categorical_accuracy: 0.9624\n",
            "Epoch 13/100\n",
            "48/48 [==============================] - 5s 106ms/step - loss: 0.1496 - sparse_categorical_accuracy: 0.9526 - val_loss: 0.1258 - val_sparse_categorical_accuracy: 0.9614\n",
            "Epoch 14/100\n",
            "48/48 [==============================] - 5s 103ms/step - loss: 0.1463 - sparse_categorical_accuracy: 0.9536 - val_loss: 0.1240 - val_sparse_categorical_accuracy: 0.9613\n",
            "Epoch 15/100\n",
            "48/48 [==============================] - 5s 103ms/step - loss: 0.1371 - sparse_categorical_accuracy: 0.9565 - val_loss: 0.1102 - val_sparse_categorical_accuracy: 0.9674\n",
            "Epoch 16/100\n",
            "48/48 [==============================] - 5s 106ms/step - loss: 0.1339 - sparse_categorical_accuracy: 0.9569 - val_loss: 0.1096 - val_sparse_categorical_accuracy: 0.9665\n",
            "Epoch 17/100\n",
            "48/48 [==============================] - 5s 104ms/step - loss: 0.1266 - sparse_categorical_accuracy: 0.9597 - val_loss: 0.1039 - val_sparse_categorical_accuracy: 0.9681\n",
            "Epoch 18/100\n",
            "48/48 [==============================] - 5s 110ms/step - loss: 0.1232 - sparse_categorical_accuracy: 0.9606 - val_loss: 0.1031 - val_sparse_categorical_accuracy: 0.9679\n",
            "Epoch 19/100\n",
            "48/48 [==============================] - 5s 104ms/step - loss: 0.1213 - sparse_categorical_accuracy: 0.9603 - val_loss: 0.1009 - val_sparse_categorical_accuracy: 0.9678\n",
            "Epoch 20/100\n",
            "48/48 [==============================] - 5s 101ms/step - loss: 0.1183 - sparse_categorical_accuracy: 0.9618 - val_loss: 0.0965 - val_sparse_categorical_accuracy: 0.9718\n",
            "Epoch 21/100\n",
            "48/48 [==============================] - 5s 106ms/step - loss: 0.1116 - sparse_categorical_accuracy: 0.9638 - val_loss: 0.0945 - val_sparse_categorical_accuracy: 0.9719\n",
            "Epoch 22/100\n",
            "48/48 [==============================] - 5s 103ms/step - loss: 0.1106 - sparse_categorical_accuracy: 0.9638 - val_loss: 0.0912 - val_sparse_categorical_accuracy: 0.9717\n",
            "Epoch 23/100\n",
            "19/48 [==========>...................] - ETA: 2s - loss: 0.1108 - sparse_categorical_accuracy: 0.9636"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-RshGA2zL3XC",
        "colab_type": "text"
      },
      "source": [
        "## Feature_extractor\n",
        "We use all but the last of the layers as a feature extractor. The output feature vector consists of 1024 numbers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7emi2ltVHyXL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "feature_extractor = tf.keras.models.Sequential(name='feature_extractor')\n",
        "feature_extractor.add(tf.keras.layers.Input(shape=(28, 28, 1)))\n",
        "for layer in model_1.layers[:-1]:\n",
        "  feature_extractor.add(layer)\n",
        "\n",
        "# Fix layers\n",
        "for ix, _ in enumerate(feature_extractor.layers):\n",
        "  feature_extractor.layers[ix].trainable = False\n",
        "print(f\"All layers frozen? {np.array([not layer.trainable for layer in feature_extractor.layers]).all()}\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vpe6ZoOGghS",
        "colab_type": "text"
      },
      "source": [
        "We can extract the feature vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zttCrssM0R_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# feature_vectors_train = feature_extractor.predict(train_dataset_labelled)\n",
        "\n",
        "for ix, (feature, label) in enumerate(test_dataset_labelled):\n",
        "  feature_vectors_batch = feature_extractor.predict(feature)\n",
        "  if ix == 0:\n",
        "    feature_vectors_test = feature_vectors_batch \n",
        "    y_true = label\n",
        "  else:\n",
        "    feature_vectors_test = np.concatenate((feature_vectors_test, feature_vectors_batch ))\n",
        "    y_true = np.concatenate((y_true, label))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NsrRa-MWRp-V",
        "colab_type": "text"
      },
      "source": [
        "#### TSNE\n",
        "Using TSNE we can visualize the embeddings in 2D. As we can see the model just trained on rotations created embeddings that can already distinguish between trousers, shirts and dresses, and footwear. In other words, it has learned a semantic feature representation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZX_Yfl4NrHi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tsne = TSNE(n_components=2, perplexity=5, learning_rate=1000, n_iter=250, verbose=1)\n",
        "results_embedded_test = tsne.fit_transform(feature_vectors_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3dtPmhtNsC_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cmap = plt.cm.jet  # define the colormap\n",
        "cmaplist = [cmap(i) for i in range(cmap.N)]\n",
        "cmaplist[0] = (.5, .5, .5, 1.0)\n",
        "\n",
        "# create the new map\n",
        "cmap = colors.LinearSegmentedColormap.from_list(\n",
        "    'Custom cmap', cmaplist, cmap.N)\n",
        "\n",
        "for l in np.unique(y_true):\n",
        "    mask = (y_true.flatten() == l)\n",
        "    plt.scatter(results_embedded_test[mask,0], results_embedded_test[mask,1], cmap=cmap, label = labelmap[l])\n",
        "plt.xlim(-10, 6)\n",
        "plt.legend(loc=3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSd7u0txz1uI",
        "colab_type": "text"
      },
      "source": [
        "# Model 2: classifier\n",
        "This model is a regular classifier for the 10 classes of the fashion mnist dataset. We use the feature extractor, trained only on rotations, and add a new top layer with softmax activation and 10 nodes. Only the top layer is trainable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "US-F34vFciQ2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# N_tot = X_train_supervised.shape[0]\n",
        "# N = min(N_tot, 100)\n",
        "N = 1000\n",
        "train_dataset_labelled = create_supervised_dataset(X_labelled[:N], y_labelled[:N]) # We train on only 100 images\n",
        "weights = compute_class_weight(class_weight='balanced', classes = np.arange(10), y = y_labelled[:N])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5Ebh2oqjIGW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_2 = tf.keras.models.Sequential([tf.keras.layers.Input(shape=(28, 28, 1)), \n",
        "                                      feature_extractor, # We do not add dropout after this layers since the parameters are anyway frozen.\n",
        "                                      # tf.keras.layers.Dropout(0.2, name='dropout'),\n",
        "                                      tf.keras.layers.Dense(units=10, activation='softmax', name='output')])\n",
        "\n",
        "model_scratch = tf.keras.models.Sequential([tf.keras.layers.Input(shape=(28, 28, 1)), \n",
        "                                            tf.keras.layers.Conv2D(32, (3, 3), activation=tf.nn.relu, padding='same', name='conv1'),\n",
        "                                            tf.keras.layers.MaxPool2D((2, 2)),\n",
        "                                            tf.keras.layers.Conv2D(64, (3, 3), activation=tf.nn.relu, padding='same', name='conv2'),\n",
        "                                            tf.keras.layers.GlobalAveragePooling2D(),\n",
        "                                            tf.keras.layers.Flatten(),\n",
        "                                            tf.keras.layers.Dropout(0.2, name='dropout'),\n",
        "                                            tf.keras.layers.Dense(units=16, activation=tf.nn.relu, name='dense'),\n",
        "                                            tf.keras.layers.Dense(units=10, activation='softmax', name='output')])\n",
        "\n",
        "# model_scratch = tf.keras.models.Sequential([tf.keras.layers.Input(shape=(32, 32, 3)), \n",
        "#                                             tf.keras.layers.Conv2D(16, (5, 5), activation=tf.nn.relu, padding='same', name='conv1'),\n",
        "#                                             tf.keras.layers.MaxPool2D((2, 2)),\n",
        "#                                             tf.keras.layers.Conv2D(32, (5, 5), activation=tf.nn.relu, padding='same', name='conv2'),\n",
        "#                                             tf.keras.layers.MaxPool2D((2, 2)),\n",
        "#                                             tf.keras.layers.Conv2D(64, (3, 3), activation=tf.nn.relu, padding='same', name='conv3'),\n",
        "#                                             tf.keras.layers.MaxPool2D((2, 2)),\n",
        "#                                             tf.keras.layers.Flatten(),\n",
        "#                                             tf.keras.layers.Dense(units=128, activation=tf.nn.relu, name='dense1'),\n",
        "#                                             tf.keras.layers.Dropout(0.2),\n",
        "#                                             tf.keras.layers.Dense(units=10, activation='softmax', name='output')])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJ4B7nIa0F6t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for layer in model_2.layers:\n",
        " if layer.name == 'feature_extractor':\n",
        "   layer.trainable=False\n",
        "\n",
        "for layer in model_2.layers:\n",
        "  print(f\"{layer.name} trainable? {layer.trainable}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-bxDlXY0OCq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_2.compile(optimizer=tf.keras.optimizers.Adam(lr=1e-2), \n",
        "                           loss='sparse_categorical_crossentropy', \n",
        "                           metrics=['sparse_categorical_accuracy'],\n",
        "                          )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5O5sG_7v0Zrk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_2.fit(train_dataset_labelled,\n",
        "      epochs=int(1e4),\n",
        "      validation_data=val_dataset_labelled, \n",
        "      callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)], \n",
        "      # class_weight=weights,\n",
        "      verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pDjdIgH_cVm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_2.evaluate(test_dataset_labelled)\n",
        "\n",
        "for ix, (feature, label) in enumerate(test_dataset_labelled):\n",
        "  pred = model_2.predict(feature).argmax(axis=1)\n",
        "  if ix == 0:\n",
        "    y_pred = pred\n",
        "    y_true = label\n",
        "  else:\n",
        "    y_pred = np.concatenate((y_pred, pred))\n",
        "    y_true = np.concatenate((y_true, label))\n",
        "\n",
        "plot_confusion_matrix(confusion_matrix(y_true, y_pred), classes = labelmap.values())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUtezkf8I3xu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_scratch.compile(optimizer=tf.keras.optimizers.Adam(lr=1e-2), \n",
        "                           loss='sparse_categorical_crossentropy', \n",
        "                           metrics=['sparse_categorical_accuracy']\n",
        "                          )\n",
        "\n",
        "model_scratch.fit(train_dataset_labelled,\n",
        "      epochs=int(1e4),\n",
        "      validation_data=val_dataset_labelled, \n",
        "      callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)], \n",
        "      verbose=1)\n",
        "\n",
        "model_scratch.evaluate(test_dataset_labelled)\n",
        "\n",
        "for ix, (feature, label) in enumerate(test_dataset_labelled):\n",
        "  pred = model_scratch.predict(feature).argmax(axis=1)\n",
        "  if ix == 0:\n",
        "    y_pred = pred\n",
        "    y_true = label\n",
        "  else:\n",
        "    y_pred = np.concatenate((y_pred, pred))\n",
        "    y_true = np.concatenate((y_true, label))\n",
        "plot_confusion_matrix(confusion_matrix(y_true, y_pred), classes = labelmap.values())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ldqnaKFJPjy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for ix, (feature, label) in enumerate(train_dataset_labelled):\n",
        "  pred = model_scratch.predict(feature).argmax(axis=1)\n",
        "  if ix == 0:\n",
        "    y_pred = pred\n",
        "    y_true = label\n",
        "  else:\n",
        "    y_pred = np.concatenate((y_pred, pred))\n",
        "    y_true = np.concatenate((y_true, label))\n",
        "\n",
        "plot_confusion_matrix(confusion_matrix(y_true, y_pred), classes = labelmap.values())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0NUcuPr55sQ5",
        "colab_type": "text"
      },
      "source": [
        "### Fine tune\n",
        "We can also fine tune this model further by opening all layers for training (this gives similar performance to just training the full model from scratch)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2_GwWImUIaL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for ix in range(len(model_2.layers)):\n",
        "  model_2.layers[ix].trainable = True\n",
        "print(f\"All layers open for training? {np.array([layer.trainable for layer in model_2.layers]).all()}\\n\")\n",
        "model_2.compile(optimizer=tf.keras.optimizers.Adam(lr=1e-4), \n",
        "                           loss='sparse_categorical_crossentropy', \n",
        "                           metrics=['sparse_categorical_accuracy']\n",
        "                          )\n",
        "\n",
        "\n",
        "\n",
        "model_2.fit(train_dataset_labelled,\n",
        "      epochs=int(1e4),\n",
        "      validation_data=val_dataset_labelled, \n",
        "      callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)], \n",
        "      verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q89dE4DUUKvi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_2.evaluate(test_dataset_labelled)\n",
        "\n",
        "for ix, (feature, label) in enumerate(test_dataset_labelled):\n",
        "  pred = model_2.predict(feature).argmax(axis=1)\n",
        "  if ix == 0:\n",
        "    y_pred = pred\n",
        "    y_true = label\n",
        "  else:\n",
        "    y_pred = np.concatenate((y_pred, pred))\n",
        "    y_true = np.concatenate((y_true, label))\n",
        "\n",
        "plot_confusion_matrix(confusion_matrix(y_true, y_pred), classes = labelmap.values())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTeiZ3jTI0xC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}